x-veld:
  code:
    about:
      description: "udpipe inference setup"
      topics: 
        - "NLP"
        - "Machine learning"
        - "tokenization"
        - "lemmatization"
        - "part of speech"
        - "dependency parsing"
        - "universal dependencies"
        - "grammatical annotation"

    inputs:
      - volume: /veld/input/1/
        file_formats: "txt"
        contents: "natural text"
      - volume: /veld/input/2/
        file_formats: "udpipe model"
        contents:
          - "NLP model"
          - "tokenizer"
          - "lemmatizer"

    outputs:
      volume: /veld/output/
      file_formats:
        - "conllu"
        - "tsv"
      contents: 
        - "tokenized text"
        - "lemmatized text"
        - "part of speech of text"
        - "universal dependencies of text"
        - "grammatically annotated text"
        - "linguistic data"

    environment:

      # input and output options
      in_txt_path:
        type: path
        path_prefix: "/veld/input/1/"
      in_model_path: 
        type: path
        path_prefix: "/veld/input/2/"
        type: "txt"
      out_conllu_path: 
        type: path
        path_prefix: "/veld/output/"

      # tokenizer options (see https://ufal.mff.cuni.cz/udpipe/1/users-manual#run_udpipe_tokenizer )
      # TODO: check for more available options
      tokenizer:
        description: "if tokenizer config should be read or not"
        type: boolean
        optional: true
        default: true
      tokenizer_normalized_spaces:
        description: "by default, UDPipe uses custom MISC fields to exactly encode spaces in the original document (as described below). If true, only the standard CoNLL-U v2 markup (SpaceAfter=No and # newpar) is used."
        type: boolean
        optional: true
        default: false
      tokenizer_presegmented:
        description: "the input file is assumed to be already segmented, with each sentence on a separate line, and is only tokenized (respecting sentence breaks)"
        type: boolean
        optional: true
        default: false
      tokenizer_ranges:
        description: "for each token, a range in the original document is stored in the format described below."
        type: boolean
        optional: true
        default: false
      tokenizer_joint_with_parsing:
        description: "an experimental mode performing sentence segmentation jointly using the tokenizer and the parser (see Milan Straka and Jana Strakov√°: Tokenizing, POS Tagging, Lemmatizing and Parsing UD 2.0 with UDPipe paper for details)."
        type: boolean
        optional: true
        default: false
      tokenizer_joint_change_boundary_logprob:
        description: "for every sentence boundary not returned by the tokenizer (i.e., either 0, 1 or 2 times). The joint sentence segmentation chooses such a segmentation, where every sentence has length at most joint_max_sentence_len and the sum of logprobs of all sentences is as large as possible."
        type: boolean
        optional: true
        default: false

      # tagger options (see https://ufal.mff.cuni.cz/udpipe/1/users-manual#run_udpipe_tagger )
      # TODO: check for more available options
      tagger:
        description: "if tagger config should be read or not"
        type: boolean
        optional: true
        default: true

      # parser options (see https://ufal.mff.cuni.cz/udpipe/1/users-manual#run_udpipe_parser )
      # TODO: check for more available options
      parser:
        description: "if parser config should be read or not"
        type: boolean
        optional: true
        default: true

services:
  veld_infer:
    build: .
    command: /veld/code/infer.sh
    volumes:
      - ./volumes/tokenize/input/1/:/veld/input/1/ 
      - ./volumes/tokenize/input/2/:/veld/input/2/
      - ./volumes/tokenize/output/:/veld/output/
      - ./src/main/:/veld/code/
    environment:
      in_txt_path: null
      in_model_path: null
      out_conllu_path: null
      tokenizer: true
      tokenizer_normalized_spaces: false
      tokenizer_presegmented: false
      tokenizer_ranges: false
      tokenizer_joint_with_parsing: false
      tokenizer_joint_change_boundary_logprob: false
      tagger: true
      parser: true
